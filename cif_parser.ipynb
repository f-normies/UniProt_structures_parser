{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b559cb3-4ca4-4a39-8311-ce8f57b0b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from Bio.PDB import MMCIFParser\n",
    "from Bio.PDB import DSSP\n",
    "from Bio.PDB.MMCIF2Dict import MMCIF2Dict\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from multiprocessing import Value\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "counter = Value('i', 0)\n",
    "\n",
    "def save_pdb_file(pdb_id, save_path):\n",
    "    file_path = os.path.join(save_path, f\"{pdb_id.upper()}.cif\")\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"File {file_path} already exists. Skipping download.\")\n",
    "        return True\n",
    "    \n",
    "    try:\n",
    "        url = f\"https://files.rcsb.org/download/{pdb_id.upper()}.cif\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        pdb_content = response.text\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(pdb_content)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch and save PDB file for PDB ID {pdb_id}: {e}\")\n",
    "        return False\n",
    "\n",
    "def save_multiple_pdb_files(df, save_path, column='PDB'):\n",
    "    if column not in df.columns:\n",
    "        print(f\"Column '{column}' not found in DataFrame.\")\n",
    "        return\n",
    "    \n",
    "    unique_pdb_ids = set()\n",
    "    for pdb_ids_str in df[column]:\n",
    "        pdb_ids = pdb_ids_str.split(';')[:-1]\n",
    "        unique_pdb_ids.update(pdb_ids)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        results = list(executor.map(lambda pdb_id: save_pdb_file(pdb_id, save_path), unique_pdb_ids))\n",
    "    \n",
    "    print(f\"Downloaded and saved {sum(results)} out of {len(unique_pdb_ids)} PDB files.\")\n",
    "\n",
    "def extract_secondary_structures(structure, file):\n",
    "    model = structure[0]\n",
    "\n",
    "    dssp = DSSP(model, file)\n",
    "    \n",
    "    data = []\n",
    "    current_ss_type = None\n",
    "    current_sequence = []\n",
    "    current_start_pos = None\n",
    "    current_end_pos = None\n",
    "    \n",
    "    for key in dssp.keys():\n",
    "        chain_id, res_id = key\n",
    "        index, aa, ss, rel_acc, phi, psi, *_ = dssp[key]\n",
    "        pos = res_id[1]\n",
    "    \n",
    "        if current_ss_type is None:\n",
    "            current_ss_type = ss\n",
    "            current_start_pos = pos\n",
    "    \n",
    "        if ss == current_ss_type:\n",
    "            current_sequence.append(aa)\n",
    "            current_end_pos = pos\n",
    "        else:\n",
    "            if current_ss_type != '-':\n",
    "                data.append([current_ss_type, ''.join(current_sequence), (current_start_pos, current_end_pos)])\n",
    "            current_ss_type = ss\n",
    "            current_sequence = [aa]\n",
    "            current_start_pos = pos\n",
    "            current_end_pos = pos\n",
    "    \n",
    "    if current_sequence and current_ss_type != '-':\n",
    "        data.append([current_ss_type, ''.join(current_sequence), (current_start_pos, current_end_pos)])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def worker(files_subset, save_cif_path):\n",
    "    global counter\n",
    "    rows = []\n",
    "    errors = []\n",
    "    for filename in files_subset:\n",
    "        if filename.endswith('.cif'):\n",
    "            filepath = os.path.join(save_cif_path, filename)\n",
    "            pdb_id = filename.split('.')[0]\n",
    "            \n",
    "            try:\n",
    "                mmcif_dict = MMCIF2Dict(filepath)\n",
    "                method = mmcif_dict.get(\"_exptl.method\", [\"Not available\"])\n",
    "                method = ', '.join(method) if isinstance(method, list) else method\n",
    "                \n",
    "                resolution = mmcif_dict.get(\"_refine.ls_d_res_high\", [\"Not available\"])\n",
    "                try:\n",
    "                    resolution = float(resolution[0]) if isinstance(resolution, list) else resolution\n",
    "                except ValueError:\n",
    "                    resolution = resolution[0] if isinstance(resolution, list) else resolution\n",
    "                \n",
    "                parser = MMCIFParser(QUIET=True)\n",
    "                structure = parser.get_structure(pdb_id, filepath)\n",
    "                \n",
    "                secondary_structures = extract_secondary_structures(structure, filepath)\n",
    "                \n",
    "                for ss_type, sequence, positions in secondary_structures:\n",
    "                    row = [pdb_id, method, resolution, sequence, ss_type, positions]\n",
    "                    rows.append(row)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                errors.append(f\"An error occurred while processing {filename}: {e}\")\n",
    "            \n",
    "            with counter.get_lock():\n",
    "                counter.value += 1\n",
    "                print(f\"Processed {counter.value} files\", end='\\r')\n",
    "    \n",
    "    return rows, errors\n",
    "\n",
    "def parse_cif_files(df, save_cif_path, num_cores=8, num_files=None):\n",
    "    global counter\n",
    "    counter.value = 0\n",
    "\n",
    "    files = os.listdir(save_cif_path)[:num_files]\n",
    "    total_files = len(files)\n",
    "    \n",
    "    print(f\"Total files to process: {total_files}\")\n",
    "\n",
    "    avg_len = total_files // num_cores\n",
    "    subsets = [files[i:i + avg_len] for i in range(0, total_files, avg_len)]\n",
    "\n",
    "    all_rows = []\n",
    "    all_errors = []\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=num_cores) as executor:\n",
    "        results = executor.map(worker, subsets, [save_cif_path]*len(subsets))\n",
    "\n",
    "    for rows, errors in results:\n",
    "        all_rows.extend(rows)\n",
    "        all_errors.extend(errors)\n",
    "\n",
    "    columns = [\"PDB\", \"Method\", \"Resolution\", \"Sequence\", \"Secondary Structure Type\", \"Positions\"]\n",
    "    df_to_append = pd.DataFrame(all_rows, columns=columns)\n",
    "    df = pd.concat([df, df_to_append], ignore_index=True)\n",
    "    \n",
    "    for error in all_errors:\n",
    "        print(error)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc525d1-7e1c-4a3b-a754-8b9fdee51f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>PDB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A009IHW8</td>\n",
       "      <td>7UWG;7UXU;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A023I7E1</td>\n",
       "      <td>4K35;4K3A;5XBZ;5XC2;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A024B7W1</td>\n",
       "      <td>5GOZ;5GP1;5H30;5H32;5H37;5IRE;5IZ7;5JMT;5KQR;5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A024SC78</td>\n",
       "      <td>4PSC;4PSD;4PSE;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A0A059TC02</td>\n",
       "      <td>4R1S;4R1T;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569347</th>\n",
       "      <td>Q9X1Q6</td>\n",
       "      <td>3DCM;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569440</th>\n",
       "      <td>Q9YC08</td>\n",
       "      <td>2CXH;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569495</th>\n",
       "      <td>Q9Z7A3</td>\n",
       "      <td>3Q9D;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569541</th>\n",
       "      <td>Q9ZB78</td>\n",
       "      <td>4XNG;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569557</th>\n",
       "      <td>Q9ZCE4</td>\n",
       "      <td>2MCQ;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33766 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Entry                                                PDB\n",
       "0       A0A009IHW8                                         7UWG;7UXU;\n",
       "1       A0A023I7E1                               4K35;4K3A;5XBZ;5XC2;\n",
       "2       A0A024B7W1  5GOZ;5GP1;5H30;5H32;5H37;5IRE;5IZ7;5JMT;5KQR;5...\n",
       "3       A0A024SC78                                    4PSC;4PSD;4PSE;\n",
       "7       A0A059TC02                                         4R1S;4R1T;\n",
       "...            ...                                                ...\n",
       "569347      Q9X1Q6                                              3DCM;\n",
       "569440      Q9YC08                                              2CXH;\n",
       "569495      Q9Z7A3                                              3Q9D;\n",
       "569541      Q9ZB78                                              4XNG;\n",
       "569557      Q9ZCE4                                              2MCQ;\n",
       "\n",
       "[33766 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_cif_path = './cif_files'\n",
    "os.makedirs(save_cif_path, exist_ok=True)\n",
    "\n",
    "dataset = pd.read_csv('uniprotkb_reviewed.tsv', sep='\\t')\n",
    "dataset.dropna(subset=['PDB'], inplace=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64be98f0-6400-43a7-bb74-a2164140d216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msave_multiple_pdb_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_cif_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 51\u001b[0m, in \u001b[0;36msave_multiple_pdb_files\u001b[1;34m(df, save_path, column)\u001b[0m\n\u001b[0;32m     48\u001b[0m     unique_pdb_ids\u001b[38;5;241m.\u001b[39mupdate(pdb_ids)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m---> 51\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpdb_id\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_pdb_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdb_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_pdb_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloaded and saved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(unique_pdb_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m PDB files.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mF:\\Programs\\Python3109\\lib\\concurrent\\futures\\_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    619\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mF:\\Programs\\Python3109\\lib\\concurrent\\futures\\_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 319\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    321\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32mF:\\Programs\\Python3109\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mF:\\Programs\\Python3109\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_multiple_pdb_files(dataset, save_cif_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc2e2e-a15f-4ebe-996e-bae859e3d208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files to process: 148595\n",
      "Processed 41161 files\r"
     ]
    }
   ],
   "source": [
    "columns = [\"PDB\", \"Method\", \"Resolution\", \"Sequence\", \"Secondary Structure Type\", \"Positions\"]\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "df = parse_cif_files(df, save_cif_path, num_cores=4, num_files=None)\n",
    "df.to_csv('secondary_structures.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3759da8-8a10-477a-abf1-4ef66b8adbcb",
   "metadata": {},
   "source": [
    "# Decypher of DSSP codes\n",
    "| Code | Structure                   |\n",
    "|------|-----------------------------|\n",
    "| H    | Alpha helix (4-12)          |\n",
    "| B    | Isolated beta-bridge residue|\n",
    "| E    | Strand                      |\n",
    "| G    | 3-10 helix                  |\n",
    "| I    | Pi helix                    |\n",
    "| T    | Turn                        |\n",
    "| S    | Bend                        |\n",
    "| -    | None                        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cf24dc-e960-4ae3-ae1e-d633ca5b85a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
